[TASK]
train = True
model_selection = False
test = True
aug = True
task = TRI-L3

[DATA]
filepath_train = ./data/MOPE/l3/train.json
filepath_dev = ./data/MOPE/l3/dev.json
filepath_test =  ./data/MOPE/l3/test_mentions_en.json
filepath_aug = ./data/MOPE/l3/epuds_en-de_de_small.json
result_file = res-test-en-tri-20000.txt

[MODEL]
#checkpoint1 = models/mBERT-MOPE-L3/run1/bert-base-multilingual-cased-finetuned-MOPE-L3_Run_1_Epochs_39
#checkpoint2 = models/mBERT-MOPE-L3/run2/bert-base-multilingual-cased-finetuned-MOPE-L3_Run_2_Epochs_45
#checkpoint3 = models/mBERT-MOPE-L3/run3/bert-base-multilingual-cased-finetuned-MOPE-L3_Run_3_Epochs_26

checkpoint1 = /ceph/inrehbei/proj/polactor/mope_tri_mbert/models/mBERT-MOPE-L3/run1/bert-base-multilingual-cased-finetuned-MOPE-L3_Run_1_Epochs_39
checkpoint2 = /ceph/inrehbei/proj/polactor/mope_tri_mbert/models/mBERT-MOPE-L3/run2/bert-base-multilingual-cased-finetuned-MOPE-L3_Run_2_Epochs_45
checkpoint3 = /ceph/inrehbei/proj/polactor/mope_tri_mbert/models/mBERT-MOPE-L3/run3/bert-base-multilingual-cased-finetuned-MOPE-L3_Run_3_Epochs_26

#bert_model = bert-base-multilingual-cased
bert_tokenizer = bert-base-multilingual-cased
model_abbr = mBERT


[PARAM]
optimizer = AdamW
epochs = 5
epochs_aug = 5 
batch_size = 16
learning_rate = 2.693154582157772e-05
eps = 5.45374378277376e-07
seed = 23  
# 18 44 23
weight_decay = 0.019840937077311938
gradient_clip = 1.0
num_warmup_steps = 0.01
print_info_every = 25 
run = 3
